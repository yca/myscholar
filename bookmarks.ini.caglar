[General]
bookmarks=scalable recognition with a vocabulary tree
notes=Shape matching and object recognition using low distortion correspondence, Robust wide baseline stereo from maximally stable extremal regions, Scale and affine invariant interest point detectors, Video Google: A text retrieval approach to object matching in videos

[quotes]
1965852ba338905b5cf8017faff09465="Object recognition is one of the core problems in computer vision, and it is a very extensively investigated topic. Due to appearance variabilities caused for example by non-rigidity, background clutter, differences in viewpoint, orientation, scale or lighting conditions, it is a hard problem."
99562334448b3d8199e7416220561cd7="The recognition of texture and object categories is\none of the most challenging problems in computer\nvision, especially in the presence of intra-class varia-\ntion, clutter, occlusion, and pose changes", "rderless\n,\ni.e., they retain only the frequencies of the\nindividual features, and discard all information about\ntheir spatial layout", "Results for the EMD kernel and the\n\x3c7\n2\nk\nernel are comparable. Either of the kernels seem\nto be a good choice for our framework, provided that\na\nsuitable vocabulary can be built efficiently"
c6635ec3b09e921ca7742d642b08c81e="the nonlinear SVM has to pay a computational complexity and a memory complexity  in the training phase, where  is the training size. Furthermore, since the number of support vectors grows linearly with , the computational complexity in testing is .", uses max spatial pooling that is more robust to local spatial translations and more biological plausible [24]., "Third, research in image statistics clearly reveals that image patches are sparse signals.", "Our experiment shows that linear kernel on histograms leads to always substantially worse results, partially due to the high quantization error of VQ", "For example, in 4, the underlying pooling function is defined as the averaging function, yielding the histogram feature.", The computed statistics by max pooling are more salient and robust to local translations
5ac30bb34671f5d738a10799e8e09cbf="As observed from our experiment, using a codebook with 2048 entries, a  image requires only 0.24 second on average for processing (including dense local descriptors extraction, LLC coding and SPM pooling to get the final representation). This efficiency significantly adds to the practical values of LLC for many real applications"
88ff541570a754f0d6b02cbf018708cb="The four main implementation choices are thus how to sample patches, how to describe them, how to characterize the resulting distributions and how to classify images based on the result.", "The\nproblem is challenging because the appearance of object instances varies sub-\nstantially owing to changes in pose, imaging and lighting conditions, occlusions\nand within-class shape variations"
477560b915efd81a600e6f33056bc725=We also show that dense representations outperform equivalent keypoint based ones on these tasks
6881163866b06a8b12e436e9ef7ed7a7="The spatial pyramids provide a reasonable cover over the image space with scale information, and most existing classification methods either use them directly, or use slightly modified/simplified versions", "We illustrate the pipeline from raw images to the prediction of class labels in Figure 1. Specifically, starting with an input image I, two stages are usually adopted to generate the global feature, as we formally define below.", "In the coding step, we extract local image patches, and encode each patch to  activation values based on a codebook of size  (learned via a separate dictionary learning step). These activations are typically binary (in the case of vector quantization) or continuous (in the case of e.g. sparse coding). It is generally believed that having an overcomplete ( the dimension of patches) codebook while keeping the activations sparse helps classification, especially when linear classifiers are used in the later steps.", "Since the coding result are highly overcomplete and highly redundant, the pooling layer aggregates the activations over certain spatial regions of the image to obtain an  dimensional vector  as the global representation of the image. Each dimension of the pooled feature  is obtained by taking the activations of one code in a specific spatial region (shown as the red rectangular in Figure 1), and performing a predefined operator (usually average or max) on the set of activations."
30ca0feb9f214df331347fd34c2ba836="The typical process to build one image feature from local features can be broken down into two steps [5]: 1) coding of local features and 2) spatial pooling of semi-local features. For each step, the embedding of spatial information has been well studied."
70a21db56f9fc29d04ca821bd6e1236b="This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods."
33aaa31e0f680ae22af1caa255b7b87a="The idea of feature\npooling originates in Hubel and Wiesel\x2019s seminal work\non complex cells in the visual cortex (\n1962\n), and is re-\nlated to Koenderink\x2019s concept of locally orderless im-\nages (\n1999\n)", "This is done by vector-\nquantizing feature descriptors and by computing the code-\nword counts over local or global areas (\nSivic & Zisserman\n,\n2003\n;\nLazebnik et al.\n,\n2006\n;\nZhang et al.\n,\n2007\n;\nYang et al.\n,\n2009\n), which is equivalent to average-pooling vectors con-\ntaining a single 1 at the index of the codeword, and 0 ev-\nerywhere else (1-of-\nk\ncodes).", "In general terms, the objective of pooling is to transform\nthe joint feature representation into a new, more usable one\nthat preserves important information while discarding ir-\nrelevant detail, the crux of the matter being to determine\nwhat falls in which category.", "chieving invariance to changes in position or\nlighting conditions, robustness to clutter, and compactne\nss\nof representation, are all common goals of pooling", "Let us examine the contribution of a single feature in a\nbag-of-features representation (i.e., if the unpooled dat\na is\na\nP\n\xd7\nk\nmatrix of 1-of-\nk\ncodes taken at\nP\nlocations, we\nextract a single\nP\n-dimensional column\nv\nof 0s and 1s, in-\ndicating the absence or presence of the feature at each lo-\ncation). For simplicity, we model the\nP\ncomponents of\nv\nas i.i.d. Bernoulli random variables. The independence as-\nsumption is clearly false since nearby image features are\nstrongly correlated, but the analysis of this simple model\nnonetheless yields useful predictions that can be verified\nempirically. The vector\nv\nis reduced by a pooling operation\nf\nto a single scalar\nf\n(\nv\n)\n(which would be one component\nof the\nk\n-dimensional representation using all features, e.g.,\none bin in a histogram). We consider two pooling types:\naverage pooling\nf\na\n(\nv\n) =\n1\nP\nP\nP\ni\n=1\nv\ni\n, and max pooling\nf\nm\n(\nv\n) = max\ni\nv\ni\n."
9d760fa986f72465e9b27928bcda11fa=and then summarizing the distribution of the codes in the cells of a spatial pyramid by some well-chosen aggregation statistic (pooling step)., "comparison: %79 performance at multiple scales and 4 point step size, %70 performance at single scale and 8 point step size."
00aea4a2b6af108045e5477d9329c2d3=computes a histogram or take the average of the codes over the region (these two methods are equivalent after normalization):
4e342a07b852f68c3a7fcc284ef2a1e5="These activations are typically binary\n(in the case of vector quantization) or continuous (in the\ncase of e.g. sparse coding), and it is generally believed that\nhaving an over-complete (\nK >\nthe dimension of patches)\ndictionary while keeping the activations sparse helps clas-\nsification, especially when linear classifiers are used in the\nlater steps.", "Each dimension of the\npooled feature\nx\ni\nis obtained by taking the activations of the\ncorresponding code in the given spatial region (also called\nreceptive field in the literature), and performing a prede-\nfined operator (usually average or max) on the set of activa-\ntions", "Since the coding result are highly over-\ncomplete and highly redundant, the pooling layer aggre-\ngates the activations over a spatial region of the image to\nobtain a\nK\ndimensional vector\nx\n"
52795d4dd784738041ecc9dbe5c91920="To make a concrete argument, we show the ScSPM computation time for encod-\ning one image as well as the performance (in Average Precision) for dictionaries\nof di\verent sizes on PASCAL VOC 2007 dataset [20], where 30,000 local descrip-\ntors are extracted from each image."
e5728df03df88ebf0f54e861dc3a8a27="When  is constrained to the set of 0\x2013\x31 vectors with only a single entry equal to 1, the encoding method is known as the hard assignment.", "Feature pooling is essentially to map the response vector  into a statistic value  via some spatial pooling operation , where  is used to summarize the joint distribution of visual features over the region of interest.", "max pooling tex: $$f_{m}({\\bf v})=\\Vert {\\bf v}\\Vert _{\\infty}=\\max_{m}\\ v_{m}.\\eqno{\\hbox{(3)}}$$", "avg pooling tex: $$f_{a}({\\bf v})={1\\over M}\\Vert {\\bf v}\\Vert_{1}={1\\over M}\\sum_{m=1}^{M}v_{m}.\\eqno{\\hbox{(2)}}$$", Also GLP outperforms all the single type of feature based methods. The performance has already exceeded the best one (82.3%) ever reported on the Caltech-101 dataset in [14].
bb6d0d1a95fa24f6827c4eeb0e9c1102="o address this challenge, we propose a fra\nmework that\nlearns object detectors using only image-level class label\ns, or so-called\nweak labels. We validate our approach on the challenging PAS\nCAL07\ndataset. Our learned detectors are comparable in accuracy w\nith state-\nof-the-art weakly supervised detection methods. More impo\nrtantly, the\nresulting OCP approach significantly outperforms SPM-base\nd pooling in\nimage classification"
e6ab0270ef0c1c63eeeef6390003045e="In BOSSA and BossaNova, we propose estimating the distribution of the descriptors around each codeword. We choose a non-parametric estimation of the descriptors distribution, by computing a histogram of distances between the descriptors found in the image and each codebook element.", "Soft-assignment coding attenuates the effect of coding errors induced by the quantization of the descriptor space. Different soft coding strategies have been presented and evaluated by Gemert et al. [6], the most successful approach being the one they call \x201c\x63odeword uncertainty\x201d. Other authors [24], [27] and [30] point out the importance of locality in the coding, an issue we will address in Section 3.4, and that leads us to a localized, \x201csemi-soft\x201d coding scheme", "The first step in that normalization is motivated by the following observation: as the number of visual words increases, BOSSA becomes sparser. That is also the case for most BoW-like representations: Perronnin et al. [12] have also observed that effect, which is indeed a direct consequence of the ratio between the number of local descriptors and the mid-level representation vector size. They observe that similarities become less reliable when the vector signatures become too sparse, proposing a power normalization to alleviate that drawback. Therefore, we choose to incorporate that normalization into the BossaNova representation.", "Table 3 also shows the comparison with published results. The comparison with [13] is particularly relevant, because we employ the same low-level descriptor extraction as them, although our representation ends up being more compact. The LLC method of [30] is evaluated with HOG descriptors. LLC was also evaluated on extremely dense SIFT descriptors (sampling step of 3 pixels, compared to 16 used in our experiments), roughly 70,000 per image, obtaining a MAP of 53.8% with a codebook of 4,000 words [20]."
83e17986ac9aeffeb6a51c0a553d3278=" The most frequent features, as noted by Jurie and Triggs [12] and others [3], [23], are not necessarily the most discriminative", "This paper presented a principal improvement on the popular codebook model for scene classification. The traditional codebook model uses hard assignment to represent image features with codewords. We replaced this basic property of the codebook approach by introducing uncertainty modeling, which is appropriate as discrete feature vectors are only capable of capturing part of the intrinsic variation in visual appearance. This uncertainty is achieved with techniques based on kernel density estimation"
4396448f729077efa59cb15c0a9d3a8b="With max-pooling, this \x201clocalized\x201d soft-assignment coding1 surprisingly catches up with or even outperforms the sparse or local coding schemes while maintaining its computational advantage.", "As shown above, max-pooling only estimates the probability of the presence of a visual word b in an image , It ignores the frequency of the occurrence of the word. In the following, we propose a \x201cmix-order\x201d max-pooling to incorporate this information", "Moreover, it even outperforms the sparse coding. Actually, merely achieving a performance comparable to sparse coding has made our method more attractive because of its much lower computational overhead. "
c99b330ed0959815b84277a115096a68=Pooling is the operation which involves aggregating several local descriptor encodings into a single representation.
ae36777875f5cabc6c034366a3c5e16d="In this paper, we review a number of techniques for generating mid-level features, including two variants of Soft Assignment, Locality-constrained Linear Coding, and Sparse Coding."
fa4227430b223bd4072d76a2b67c3a4a="Comparison of different encoding methods on KTH: Vector Quanti-\nzation(VQ), Soft-assignment Encoding(SA-k), Fisher Kernel Encoding(FK), Local-\nconstrain Linear Encoding(LLC) and Sparse Encoding(SPC)", Comparison our proposed methods with state of the art on HMDB51
04ace1329d025214701ff101f222bc77=caglar: This paper shows that not all of the datasets react well to multiple features.

[search]
nokey=Shape matching and object recognition using low distortion correspondence, Robust wide baseline stereo from maximally stable extremal regions, Scale and affine invariant interest point detectors, Video Google: A text retrieval approach to object matching in videos, The importance of encoding versus training with sparse coding and vector quantization

[read]
nokey=Representing shape with a spatial pyramid kernel, SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition, In defense of Nearest-Neighbor based image classification, spatial pyramid pooling in deep convolutional networks for visual recognition, deformable spatial pyramid matching for fast dense correspondences, pooling-invariant image feature learning, Constrained parametric min cuts for automatic object segmentation., in defense of soft-assignment coding

[readby]
caglar=cafedcc0b42be8546a9e05f64ea91816, 390052000754e4fc1363852db37dca02, c6635ec3b09e921ca7742d642b08c81e, b652097aec018f67ad3ce7a9d3f20fef, 1965852ba338905b5cf8017faff09465, 99562334448b3d8199e7416220561cd7, 5ac30bb34671f5d738a10799e8e09cbf, 88ff541570a754f0d6b02cbf018708cb, 477560b915efd81a600e6f33056bc725, 6881163866b06a8b12e436e9ef7ed7a7, c82cdb776f1a350a21a4b47c04916151, 95485a27d4743b848eb26942e6dedb6c, ec5f7635513d740327ccc4e4d2e13cb9, 33aaa31e0f680ae22af1caa255b7b87a, 00aea4a2b6af108045e5477d9329c2d3, 9d760fa986f72465e9b27928bcda11fa, 4e342a07b852f68c3a7fcc284ef2a1e5, e5728df03df88ebf0f54e861dc3a8a27, 16a1dd1f068cd8c29928dd1bbdd0f8a0, bb6d0d1a95fa24f6827c4eeb0e9c1102, e6ab0270ef0c1c63eeeef6390003045e, 83e17986ac9aeffeb6a51c0a553d3278, 4396448f729077efa59cb15c0a9d3a8b, fa4227430b223bd4072d76a2b67c3a4a, b5d9a66e8f9f8bf14e2c0bce2f1a6738, e5367706a8abb39e05e851695c9835b9

[seenby]
caglar=30ca0feb9f214df331347fd34c2ba836, 599d64e5c2d92fbb85010509d9519463, 5b443513297af397712b8efcc706d079, 1f263122482fba209dc9fe67480a46d7, b51948adaaaf62c6aee8c2115bd9f965, 52795d4dd784738041ecc9dbe5c91920, e899bdcab7e3a0f2632085971993c121, c99b330ed0959815b84277a115096a68

[irrelevant]
nokey=f1602150b4f6a2a838108bb3008febab, 82485031bac35d685c1245a88e2799e3, b2118b2074d40afd5d065bfc830ffffd

[keyword]
nokey=semantic modeling
